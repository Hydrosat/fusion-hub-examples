{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ecfbed",
   "metadata": {},
   "source": [
    "# Fusion Hub Data Quick-Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db7c51e",
   "metadata": {},
   "source": [
    "This notebook demonstrates the process of:\n",
    "* Searching a collection to intersect a point location between a start data and end date\n",
    "* Converting the search result to an `xarray` DataArray\n",
    "* Subsetting the DataArray to a geometry\n",
    "* Plotting the time series in a grid\n",
    "* Extracting data from a point location\n",
    "* Reducing the data within a geometry\n",
    "* Downloading a file based on valid data percentage\n",
    "* Downloading multiple files\n",
    "* Removing data entries based on some condition\n",
    "* Creating matplotlib animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pystac\n",
    "from pystac_client import Client\n",
    "from pprint import pprint\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from shapely.geometry import box, mapping, Point, Polygon\n",
    "from pyproj.crs import CRS\n",
    "import geopandas as gpd\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1f0f6-8d3b-4a3a-b25b-3baca3b63dc3",
   "metadata": {},
   "source": [
    "If you see `ERROR 1: PROJ: proj_create_from_database: Open of /opt/conda/share/proj failed`, do not fret, and proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c422bd-7006-4992-9532-9d1d71979697",
   "metadata": {},
   "source": [
    "This next cell opens a file `creds.json` which you will need to create in the same directory as the notebook. The format of the file should be:\n",
    "\n",
    "```\n",
    "{\n",
    "\"username\":\"your_username\",\n",
    "\"password\":\"your_password\"\n",
    "}\n",
    "```\n",
    "\n",
    "and you have updated with your username and password. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6f7f9-8060-44e5-875d-695a37f24cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creds.json') as f:\n",
    "    creds = json.loads(f.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760f616-4cf5-4775-82aa-74051f55c17b",
   "metadata": {},
   "source": [
    "This next cell will endecode the `username:password` combination and use it to authorize access to the STAC API given by the `cat_url` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "userpass = f\"{creds['username']}:{creds['password']}\"\n",
    "b64 = base64.b64encode(userpass.encode()).decode()\n",
    "headers = {'Authorization':'Basic ' + b64}\n",
    "\n",
    "cat_url = 'https://fusion-stac.hydrosat.com'\n",
    "catalog = Client.open(cat_url, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc4849",
   "metadata": {},
   "source": [
    "We'll search for data in the `starfm_predictions_modis_landsat` and `pydms_sharpened_landsat` collections which intersect a point location between a start date and an end date and print out the number of items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = {'type': 'Point', 'coordinates': [-120.21102905273436,36.535019209789]} # Point for Hanford, CA, USA\n",
    "\n",
    "collections = [\"starfm_predictions_modis_landsat\", \"pydms_sharpened_landsat\"]\n",
    "start_date = \"2021-08-17T00:00:00Z\"\n",
    "end_date = \"2021-10-30T00:00:00Z\"\n",
    "\n",
    "search = catalog.search(\n",
    "    collections = collections,\n",
    "    intersects = geom,\n",
    "    datetime = [start_date, end_date],\n",
    "    max_items = 500\n",
    ")\n",
    "\n",
    "# items = list(search.items()) # for pystac-client >= 0.4.0\n",
    "items = list(search.get_all_items()) # for pystac-client < 0.4.0\n",
    "items.reverse() # make the results ascending in time\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced2d9f",
   "metadata": {},
   "source": [
    "This next cell will determine if the data returned covers more than a single MGRS tile. If there is, choose one of the tiles to subset the list of returned items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea830956",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgrs_tiles = []\n",
    "for i in items:\n",
    "    for l in i.to_dict()['links']:\n",
    "        if 'element84' in l['href']:\n",
    "            mgrs_tiles.append(l['href'].split(r'/')[-1].split('_')[1])\n",
    "print(f'number of tiles in query: {len(set(mgrs_tiles))}, {set(mgrs_tiles)}')\n",
    "\n",
    "# if there is more than one tile, uncomment and execute this next line to choose the MGRS tile you are interested in\n",
    "# items = [i for i in items if mgrs_tiles[0] in i.id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd358be",
   "metadata": {},
   "source": [
    "Now we'll pass the first 25 items to the `FH_Hydrosat` class and stack the items into an `xarray` `DataArray`. We'll print out the DataArray to get a summary of its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from FH_Hydrosat import FH_Hydrosat\n",
    "res = FH_Hydrosat(items[:25])\n",
    "stacked_res = res.stack()\n",
    "stacked_res.ds.sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d450b-f3a1-447b-8c10-9d507f9e18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = stacked_res.ds.sortby('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11fba0",
   "metadata": {},
   "source": [
    "The `DataArray` is quite large if we try to access all of the data. For ease of computation, we'll subset the `DataArray` by a polygon, which will be generated by creating a rectangular buffer around the point location by 1km on either side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_geom = Point(geom['coordinates'][0], geom['coordinates'][1])\n",
    "point_df = gpd.GeoDataFrame({'geometry':[p_geom]}, crs=CRS.from_epsg(4326))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_crs = CRS.from_wkt(ds.spatial_ref.crs_wkt)\n",
    "buffer_dist = 1000 # 1km in local UTM zone\n",
    "poly_df = point_df.to_crs(raster_crs).buffer(buffer_dist, cap_style = 3) # square buffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b0e13",
   "metadata": {},
   "source": [
    "Let's plot the polygon on a Folium map so we can see where we are extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a755eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium \n",
    "\n",
    "# Use WGS 84 (epsg:4326) as the geographic coordinate system\n",
    "df = gpd.GeoDataFrame(poly_df.to_crs(epsg=4326))\n",
    "\n",
    "m = folium.Map(location=[p_geom.y, p_geom.x], zoom_start=13, tiles='CartoDB positron')\n",
    "\n",
    "# add the polygon and centroid\n",
    "for _, r in df.iterrows():\n",
    "    # Without simplifying the representation of each polygon,\n",
    "    # the map might not be displayed\n",
    "    #sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)\n",
    "    sim_geo = r[0].simplify(tolerance=0.001)\n",
    "    geo_j = gpd.GeoSeries(sim_geo).to_json()\n",
    "    geo_j = folium.GeoJson(data=geo_j,\n",
    "                           style_function=lambda x: {'fillColor': 'orange'})\n",
    "    \n",
    "    geo_j.add_to(m)\n",
    "    \n",
    "    lat = sim_geo.centroid.y\n",
    "    lon = sim_geo.centroid.x\n",
    "    folium.Marker(location=[lat, lon]).add_to(m)\n",
    "    \n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672cade",
   "metadata": {},
   "source": [
    "Now let's clip the dataset with the geometry using `rioxarray`'s `rio` utility package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624eb76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from FH_Hydrosat import FH_StackedDataset\n",
    "\n",
    "# clip the raster dataset and cast to a class with slightly more functions\n",
    "clipped = FH_StackedDataset(ds.rio.clip(poly_df.geometry))\n",
    "ds_clip = clipped.ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469683f",
   "metadata": {},
   "source": [
    "Now that we have a smaller `DataArray`, let's plot the contents according to the `time` dimension using `xarray`'s plot utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36ccf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_clip.plot(x='x', y='y', col='time', col_wrap=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd7536",
   "metadata": {},
   "source": [
    "## Plot a time series for the point location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3510f3",
   "metadata": {},
   "source": [
    "With the same `DataArray`, we can extract the pixel values which intersect a point location. Let's use the same point location we used to search the STAC catalog and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae82823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centroid = poly_df.geometry[0].centroid\n",
    "set_x, set_y, pixtype = (centroid.x, centroid.y, 'Center Pixel') # change 'Center Pixel' for plot title\n",
    "\n",
    "ax = ds_clip.plot(x='x', y='y', col='time', col_wrap=5)\n",
    "ax.set_xlabels('Easting [m]')\n",
    "ax.set_ylabels('Northing [m]')\n",
    "ax.map(lambda: plt.plot(set_x, set_y, markersize=20, marker=\".\", color=\"m\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ax = ds_clip.isel(band=0).sel(x=set_x, y=set_y, method='nearest', tolerance=20).plot(marker='o', c='m', figsize=(12,7))\n",
    "plt.title(f'time series for {pixtype} pixel')\n",
    "plt.grid(True)\n",
    "plt.ylabel('Fused LST [K]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ba1c4",
   "metadata": {},
   "source": [
    "Similarly, we can reduce the area within the subsetting geometry to the mean value, and plot against the time series for the point location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b282e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = ds_clip.plot(x='x', y='y', col='time', col_wrap=5)\n",
    "ax.set_xlabels('Easting [m]')\n",
    "ax.set_ylabels('Northing [m]')\n",
    "ax.map(lambda: plt.plot(set_x, set_y, markersize=20, marker=\".\", color=\"m\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ax = ds_clip.isel(band=0).sel(x=set_x, y=set_y, method='nearest', tolerance=20).plot(linestyle='--', marker='o', c='m', label='Point location', figsize=(12,7))\n",
    "ax = ds_clip.isel(band=0).mean(dim=('x', 'y')).plot(linestyle='--', marker='o', c='b', label='Area mean')\n",
    "plt.title(f'time series for {pixtype} pixel')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylabel('Fused LST [K]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7d66a",
   "metadata": {},
   "source": [
    "## download a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e742f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which file has the most data in it\n",
    "max_data_idx = np.argmax(ds_clip.count(dim=('x', 'y', 'band')).values)\n",
    "\n",
    "outfile = f'./{os.path.basename(res.item_desc[max_data_idx])}'\n",
    "print(outfile, os.path.exists(outfile))\n",
    "\n",
    "res.download_single_asset(max_data_idx)\n",
    "\n",
    "print(outfile, os.path.exists(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ac51a",
   "metadata": {},
   "source": [
    "## download multiple files, since there a few scenes that have full coverage for the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e538562-c203-44a9-81c4-a6cf4d936add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the items above which correspond to items 2,5,6, and 10\n",
    "# using the download_multiple_assets() function\n",
    "res.download_multiple_assets([2,5,6,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef9056-610e-4cfc-930a-16df5575ba1e",
   "metadata": {},
   "source": [
    "## make an animation from the full set of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131563c-cb10-4703-ab2b-81bbcbd9cbdf",
   "metadata": {},
   "source": [
    "If you see `Javascript Error: IPython is not defined` or `MovieWriter ffmpeg unavailable; using Pillow instead`, do not fret, and proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048bb69-6730-4004-9fc7-3d45ef204a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# switch plotting to allow for animations\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the create_animation() function.\n",
    "# display the animation with HTML display\n",
    "ani = clipped.create_animation(save_ani=True, vmin=300, vmax=350)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1940b7-7f23-4240-8253-70a4c00e5e56",
   "metadata": {},
   "source": [
    "### drop files with data less than 50% coverage\n",
    "Sometimes the data will have low coverage due to cloud cover or invalid pixels in the input data products. Let's remove them from the dataset using the `remove_below_data_perc()` function, plot them, and create an animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae535e-9a76-436b-9f0e-36bf30cc1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to switch back and allow xarray plots\n",
    "%matplotlib inline \n",
    "\n",
    "more_data = FH_StackedDataset(clipped.remove_below_data_perc(clipped.ds, 0.5))\n",
    "ax = more_data.ds.plot(x='x', y='y', col='time', col_wrap=5)\n",
    "ax.set_xlabels('Easting [m]')\n",
    "ax.set_ylabels('Northing [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9111f-c1fd-4a4d-bfe6-bc948f9d611d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # switch back to allow animation\n",
    "%matplotlib notebook\n",
    "ani = more_data.create_animation(save_ani=True, vmin=300, vmax=350, anipath='more_data.gif')\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55987c1-2564-40bc-bb48-8225f59deb33",
   "metadata": {},
   "source": [
    "You may notice that the animation plays with the most recent date in the data stack first, and then ascending. To reverse the order to descending from the last date in the dataset, use an `xarray` call to reverse the `time` dimension on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2b702-1ac7-4b15-a65a-f576bf5463fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the order\n",
    "more_data_rev = FH_StackedDataset(more_data.ds.sortby('time', ascending=False))\n",
    "ani = more_data_rev.create_animation(save_ani=True, vmin=300, vmax=350, anipath='more_data_rev.gif')\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5712bf-565c-44d3-be9c-bd678f9171ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "execution": {
   "timeout": -1
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
